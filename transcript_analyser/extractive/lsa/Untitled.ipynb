{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "87ada2df-d862-4be8-af94-14028fe17b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcript_analyser import Transcript\n",
    "from transcript_analyser.utils.utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "abf2b1ac-fd78-41d0-bb92-d439fa9bf823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('transcript_analyser/sample_data/sample_01.json', 'r') as f:\n",
    "    json_obj = json.load(f)\n",
    "    f.close()\n",
    "transcript = Transcript(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "4683d6a4-f1d6-4938-96e7-36d429965c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Uh huh  mary  hi  hello, I'm Susan Thompson Resource manager.  Hi, I'm mary Hanson and I'm applying for one of your kitchen jobs.  Great,  here's a copy of my resume.  Great, have a seat mary.Thank you.  Mary, do you have any experience working in the kitchen?  No,  but I want to learn,  I work hard and  I cook a lot at home.  Okay,  well tell me about yourself.  Well  I love to learn new things.  I'm very  organized  and  I follow directions. Exactly.  That's why my boss at my last  job  made me a trainer  and the company actually gave me a special certificate  for coming to work  on time  every day for a year  and  I'm taking an  english class to  improve my writing skills.  That's.Great.  Why did you leave your last job?  It was  graveyard  and  I need to work  days.  Oh I see.  Well what hours can you.Work  from eight am until five pm.  Okay well do you have any questions for me mary?  Yes.  What  kind of training is needed?  Not a lot.  Most new workers can learn everything the  first day.  Do you have any other questions?  No, I don't think so,  but I've heard a lot of good things about your company and I would really like to work here.  Well I have a few more interviews to do today  but I will call you tomorrow if you get the job.  Okay, you are sure. Nice to meet you. Nice meeting.You too. Thank you so much for your time.  Yes, good luck. Thank you.\""
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "67c58f29-3395-4d50-a778-d3ee5ddcc938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "stop_words = Utils.load_stop_words()\n",
    "sents = sent_tokenize(transcript.text)\n",
    "sents = [\n",
    "    ' '.join([word.lower() for word in sent.split()])\n",
    "    for sent in sents\n",
    "]\n",
    "\n",
    "sents = [\n",
    "    sent for sent in sents\n",
    "    if len(sent.split()) > 4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ca463890-50fc-42e0-8827-b492e6fc489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from numpy.linalg import svd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "87c9c3d7-4e00-437d-a8f9-f45210b464df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=stop_words, min_df=2)\n",
    "bows = vectorizer.fit_transform(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "34abe914-5b4c-4b2a-a03f-105b25bf27d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 20)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bows = bows.todense().A.T\n",
    "bows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4cb0359a-ae09-4c5f-83aa-24c84b8213c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['company', 'day', 'great', 'job', 'kitchen', 'learn', 'lot',\n",
       "       'mary', 'questions', 'things', 'time', 'work'], dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4df843cd-d31a-4074-8900-47aac5fd343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulted array after using SVD on the data: ((12, 12), (12,), (12, 20))\n"
     ]
    }
   ],
   "source": [
    "u, sigma, vt = singular_value_decomposition(bows, full_matrices=False)\n",
    "\n",
    "print(f'resulted array after using SVD on the data: {u.shape, sigma.shape, vt.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e5878e01-430b-4aec-ad01-af05b6975661",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_concepts = 3\n",
    "n_sentences = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0317fc-55a4-4fc9-9c89-d560ede6fdf8",
   "metadata": {},
   "source": [
    "Gong and Liu (2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e75248db-4a38-4098-9f7c-7833c2031ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uh huh mary hi hello, i'm susan thompson resource manager.\n",
      "why did you leave your last job?\n",
      "it was graveyard and i need to work days.\n"
     ]
    }
   ],
   "source": [
    "vt_v1 = vt[:n_concepts,].copy()\n",
    "indices = []\n",
    "for i in range(n_concepts):\n",
    "    sent_index = np.argmax(np.abs(vt_v1[i, :]))\n",
    "    indices.append(sent_index)\n",
    "for index in sorted(indices):\n",
    "    print(sents[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b617c8-36e3-406a-8908-dff6003f656d",
   "metadata": {},
   "source": [
    "Steinberger and Jezek (2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a7eed2db-8d86-4ceb-bde3-139009e53ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uh huh mary hi hello, i'm susan thompson resource manager.\n",
      "why did you leave your last job?\n",
      "it was graveyard and i need to work days.\n"
     ]
    }
   ],
   "source": [
    "vt_v2 = (vt.copy())[:n_concepts, ]\n",
    "sigma_v2 = (sigma.copy())[:n_concepts]\n",
    "indices = []\n",
    "\n",
    "for i in range(vt_v2.shape[1]):\n",
    "    vt_v2[:, i] = np.multiply(vt_v2[:, i], sigma_v2)\n",
    "\n",
    "for i in range(vt_v2.shape[0]):\n",
    "    sent_index = np.argmax(np.abs(vt_v2[i, :]))\n",
    "    indices.append(sent_index)\n",
    "for index in sorted(indices):\n",
    "    print(sents[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ab08ea95-bbf6-46c3-840b-2b8abab09bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "okay, well tell me about yourself.\n",
      "why did you leave your last job?\n",
      "what kind of training is needed?\n",
      "well i have a few more interviews to do today but i will call you tomorrow if you get the job.\n",
      "thank you so much for your time.\n"
     ]
    }
   ],
   "source": [
    "vt_v3 = (vt.copy())[:n_concepts, ]\n",
    "sigma_v3 = (sigma.copy())[:n_concepts]\n",
    "\n",
    "indices = []\n",
    "sentence_scores_v3 = []\n",
    "for sent in vt_v3.T:\n",
    "    sentence_scores_v3.append(np.dot(sent, sigma_v3))\n",
    "indices = np.argsort(sentence_scores_v3)[:n_sentences]\n",
    "for index in sorted(indices):\n",
    "    print(sents[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c17562-9763-426d-8c4b-218b5ca75cb3",
   "metadata": {},
   "source": [
    "Cross method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d26d88d2-bade-438c-89fc-9f79d273f3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great, here's a copy of my resume.\n",
      "okay, well tell me about yourself.\n",
      "i'm very organized and i follow directions.\n",
      "what kind of training is needed?\n",
      "thank you so much for your time.\n"
     ]
    }
   ],
   "source": [
    "vt_v4 = (vt.copy())[:n_concepts, ]\n",
    "sigma_v4 = (sigma.copy())[:n_concepts]\n",
    "\n",
    "concepts_mean_scores = np.mean(vt_v4, axis = 1)\n",
    "for concept_id in range(vt_v4.shape[0]):\n",
    "    vt_v4[concept_id, :] = np.multiply(vt_v4[concept_id, :], vt_v4[concept_id, :] > concepts_mean_scores[concept_id])\n",
    "    \n",
    "sentence_scores = np.sum(vt_v4, axis = 0)\n",
    "sentence_indices = np.argsort(sentence_scores)[:n_sentences]\n",
    "for index in sorted(sentence_indices):\n",
    "    print(sents[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8af14e11-53d4-4859-96ea-26b20a952060",
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_v5 = (vt.copy())[:n_concepts, ]\n",
    "sigma_v5 = (sigma.copy())[:n_concepts]\n",
    "\n",
    "concepts_mean_scores = np.mean(vt_v5, axis = 1)\n",
    "for concept_id in range(vt_v5.shape[0]):\n",
    "    vt_v5[concept_id, :] = np.multiply(vt_v5[concept_id, :], vt_v5[concept_id, :] > concepts_mean_scores[concept_id])\n",
    "    \n",
    "\n",
    "concept_concept_matrix = np.zeros((n_concepts, n_concepts))\n",
    "for i in range(n_concepts):\n",
    "    for j in range(n_concepts):\n",
    "        a = vt_v5[i, :]\n",
    "        b = vt_v5[j, :]\n",
    "        both_non_zero_mask = np.multiply(a != 0, b != 0)\n",
    "        concept_concept_matrix[i, j] = np.sum(np.multiply(both_non_zero_mask, a)) + np.sum(np.multiply(both_non_zero_mask, b))\n",
    "\n",
    "strength_values = np.sum(concept_concept_matrix, axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
