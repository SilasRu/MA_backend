{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb7a7e9f-6c77-4d9b-bfc2-6258c8630de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Transcript_Analysis import *\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62a9c6bf-7cea-4743-8c03-32d3696870f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '/Users/user/Documents/dialogue_summarization/transcriptsforkeyphraseextraction'\n",
    "filename = '2021-07-12 14.35.38 Interscriber Wrapup.m4a.csv'\n",
    "\n",
    "df = pd.read_csv(os.path.join(dirname, filename))\n",
    "utterances = df['Utterance'].tolist()\n",
    "text = ' '.join(utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aaea809c-4221-435d-bdbb-c34efbe4b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e0d2b73-cd88-476e-9f46-f64106e8489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "model = BartModel.from_pretrained(\"facebook/bart-large\", output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4bf6c28e-73df-4844-9727-5a76c8fbd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sentences[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8789d019-cf1e-41b3-b665-163b42a6f6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', '.', 'ĠHello', 'Ġeverybody', '.', 'ĠOkay', '.', 'ĠUm', 'Ġjust', 'Ġa']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(sample)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1004ca4-024e-4641-b6c9-d5ddff7d2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(text, max_len = 800):\n",
    "    tokenized_sents = text.split()\n",
    "    length = len(tokenized_sents)\n",
    "    num_chunks = length // max_len\n",
    "    tokenized_sents_chunks = [' '.join(tokenized_sents[i:min(length, i + max_len)]) for i in range(0, length, max_len)]\n",
    "    return tokenized_sents_chunks\n",
    "\n",
    "tokenized_sents_chunks = get_chunks(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cae90e28-f9a7-4328-ba76-806c5a9f2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2e94f07-6706-49d4-97ff-e7f11173a6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Um just a remark at the beginning, I am recording this meeting because we need some templates for our next step of interscriber to summarize meetings, and we need some English samples.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks = get_chunks(sample)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb9190a8-d6e9-4581-a0b3-7f8918904c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_hidden_state(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', add_special_tokens=False)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.squeeze().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd254461-4d65-476b-b1c8-ae58d5e253e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac83a6c9fb0f478890f17310ea528454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chunks = get_chunks(text)\n",
    "chunks = sentences\n",
    "last_hidden_states = np.zeros((len(chunks), 1024))\n",
    "for i, chunk in enumerate(chunks):\n",
    "    last_hidden_states[i] = np.mean(get_last_hidden_state(chunk), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f9075-9daf-407c-adc9-9cb28a520f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
